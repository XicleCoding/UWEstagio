{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "c:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BART_classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "#mDeBERTa_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cenas:4\n",
      "Sectors:11\n",
      "Industry Groups:24\n",
      "Industries:68\n",
      "Sub-Industries:155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df=pd.read_csv('india-news-headlines.csv')\n",
    "df2 = pd.read_csv('datasets/US_stocks.csv')\n",
    "\n",
    "df2.drop(['Ticker', 'Company Name', 'Comment'], inplace=True, axis=1)\n",
    "\n",
    "df2_sector = df2.drop(['Industry Group', 'Industry', 'Sub-Industry'], axis=1)\n",
    "df2_industry_group = df2.drop(['Sector', 'Industry', 'Sub-Industry'], axis=1)\n",
    "df2_industry = df2.drop(['Industry Group', 'Sector', 'Sub-Industry'], axis=1)\n",
    "df2_sub_industry = df2.drop(['Industry Group', 'Industry', 'Sector'], axis=1)\n",
    "\n",
    "#df2.head(n=10)\n",
    "test=df2_sector.head(n=10)\n",
    "print(f\"cenas:{len(test['Sector'].unique())}\")\n",
    "#df2_industry_group.head(n=10)\n",
    "#df2_industry.head(n=10)\n",
    "#df2_sub_industry.head(n=10)\n",
    "#df2_sector.values[0]\n",
    "\n",
    "num_sector=len(df2_sector['Sector'].unique())\n",
    "num_industry_group=len(df2_industry_group['Industry Group'].unique())\n",
    "num_industry=len(df2_industry['Industry'].unique())\n",
    "num_sub_industry=len(df2_sub_industry['Sub-Industry'].unique())\n",
    "\n",
    "print(f'Sectors:{num_sector}\\nIndustry Groups:{num_industry_group}\\nIndustries:{num_industry}\\nSub-Industries:{num_sub_industry}')\n",
    "len(df2_sector['Description'].iloc[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m         chunks \u001b[39m=\u001b[39m split_text(text)\n\u001b[0;32m     40\u001b[0m         translated_chunks \u001b[39m=\u001b[39m [translate_chunk(chunk) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks]\n\u001b[1;32m---> 41\u001b[0m         translated_texts\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(translated_chunks))\n\u001b[0;32m     44\u001b[0m \u001b[39m'''def translate_text(text):\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m    translator = Translator(from_lang='en', to_lang='pt')  # Translate from English ('en') to Portuguese ('pt')\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m    try:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39m        print(f\"Error translating text: {e}\")\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39m        return ''  # Return empty string or any other default value'''\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39m# Assuming you have a DataFrame called 'df'\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m# Replace 'your_target_column' with the name of the column you want to translate\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from translate import Translator\n",
    "\n",
    "translator = Translator(from_lang='en', to_lang='pt')  # Translate from English ('en') to Portuguese ('pt')\n",
    "\n",
    "'''try:\n",
    "        translated = translator.translate(text)\n",
    "        return translated\n",
    "    except Exception as e:\n",
    "        # Handle translation errors\n",
    "        print(f\"Error translating text: {e}\")\n",
    "        return ''  # Return empty string or any other default value\n",
    "'''\n",
    "\n",
    "# Function to translate a text chunk\n",
    "def translate_chunk(chunk):\n",
    "    #try:\n",
    "    translated = translator.translate(chunk)\n",
    "    #except Exception as e:\n",
    "    #    print(f\"Error translating text: {e}\")\n",
    "    #    return ''  # Return empty string or any other default value\n",
    "\n",
    "    '''translation = translate_client.translate(chunk, target_language='your_target_language')\n",
    "    return translation['translatedText']\n",
    "'''\n",
    "# Function to break the text into chunks of maximum length (500 characters)\n",
    "def split_text(text, chunk_size=500):\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# Column containing text to translate\n",
    "column_name = 'Description'\n",
    "\n",
    "# Translate the column with more than 500 characters\n",
    "translated_texts = []\n",
    "for text in test[column_name]:\n",
    "    if len(text) <= 500:\n",
    "        translated_texts.append(translate_chunk(text))\n",
    "    else:\n",
    "        chunks = split_text(text)\n",
    "        translated_chunks = [translate_chunk(chunk) for chunk in chunks]\n",
    "        translated_texts.append(''.join(translated_chunks))\n",
    "\n",
    "\n",
    "'''def translate_text(text):\n",
    "    translator = Translator(from_lang='en', to_lang='pt')  # Translate from English ('en') to Portuguese ('pt')\n",
    "    try:\n",
    "        translated = translator.translate(text)\n",
    "        return translated\n",
    "    except Exception as e:\n",
    "        # Handle translation errors\n",
    "        print(f\"Error translating text: {e}\")\n",
    "        return ''  # Return empty string or any other default value'''\n",
    "\n",
    "# Assuming you have a DataFrame called 'df'\n",
    "# Replace 'your_target_column' with the name of the column you want to translate\n",
    "test['translated_text'] = test['Description'].apply(translate_text)\n",
    "\n",
    "# Now the 'translated_text' column contains the translated values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     translated_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(translated_columns)\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m translated_df\n\u001b[1;32m---> 14\u001b[0m translated_df \u001b[39m=\u001b[39m translate_dataframe(test)\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(translated_df)\n",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m, in \u001b[0;36mtranslate_dataframe\u001b[1;34m(df, target_language)\u001b[0m\n\u001b[0;32m      6\u001b[0m translated_columns \u001b[39m=\u001b[39m {}\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m----> 8\u001b[0m     translations \u001b[39m=\u001b[39m [translator\u001b[39m.\u001b[39mtranslate(text, src\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39men\u001b[39m\u001b[39m'\u001b[39m, dest\u001b[39m=\u001b[39mtarget_language)\u001b[39m.\u001b[39mtext \u001b[39mif\u001b[39;00m text \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m df[col]\u001b[39m.\u001b[39mtolist()]\n\u001b[0;32m      9\u001b[0m     translated_columns[col] \u001b[39m=\u001b[39m translations\n\u001b[0;32m     11\u001b[0m translated_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(translated_columns)\n",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m translated_columns \u001b[39m=\u001b[39m {}\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m----> 8\u001b[0m     translations \u001b[39m=\u001b[39m [translator\u001b[39m.\u001b[39;49mtranslate(text, src\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m, dest\u001b[39m=\u001b[39;49mtarget_language)\u001b[39m.\u001b[39mtext \u001b[39mif\u001b[39;00m text \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m df[col]\u001b[39m.\u001b[39mtolist()]\n\u001b[0;32m      9\u001b[0m     translated_columns[col] \u001b[39m=\u001b[39m translations\n\u001b[0;32m     11\u001b[0m translated_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(translated_columns)\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\googletrans\\client.py:182\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    181\u001b[0m origin \u001b[39m=\u001b[39m text\n\u001b[1;32m--> 182\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_translate(text, dest, src, kwargs)\n\u001b[0;32m    184\u001b[0m \u001b[39m# this code will be updated when the format is changed.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m translated \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([d[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m d[\u001b[39m0\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data[\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\googletrans\\client.py:78\u001b[0m, in \u001b[0;36mTranslator._translate\u001b[1;34m(self, text, dest, src, override)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_translate\u001b[39m(\u001b[39mself\u001b[39m, text, dest, src, override):\n\u001b[1;32m---> 78\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken_acquirer\u001b[39m.\u001b[39;49mdo(text)\n\u001b[0;32m     79\u001b[0m     params \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mbuild_params(query\u001b[39m=\u001b[39mtext, src\u001b[39m=\u001b[39msrc, dest\u001b[39m=\u001b[39mdest,\n\u001b[0;32m     80\u001b[0m                                 token\u001b[39m=\u001b[39mtoken, override\u001b[39m=\u001b[39moverride)\n\u001b[0;32m     82\u001b[0m     url \u001b[39m=\u001b[39m urls\u001b[39m.\u001b[39mTRANSLATE\u001b[39m.\u001b[39mformat(host\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pick_service_url())\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\googletrans\\gtoken.py:194\u001b[0m, in \u001b[0;36mTokenAcquirer.do\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update()\n\u001b[0;32m    195\u001b[0m     tk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macquire(text)\n\u001b[0;32m    196\u001b[0m     \u001b[39mreturn\u001b[39;00m tk\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\googletrans\\gtoken.py:62\u001b[0m, in \u001b[0;36mTokenAcquirer._update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m# this will be the same as python code after stripping out a reserved word 'var'\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m code \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mRE_TKK\u001b[39m.\u001b[39;49msearch(r\u001b[39m.\u001b[39;49mtext)\u001b[39m.\u001b[39;49mgroup(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mvar \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[39m# unescape special ascii characters such like a \\x3d(=)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m code \u001b[39m=\u001b[39m code\u001b[39m.\u001b[39mencode()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39municode-escape\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def translate_dataframe(df, target_language='pt'):\n",
    "    translator = Translator()\n",
    "\n",
    "    translated_columns = {}\n",
    "    for col in df.columns:\n",
    "        translations = [translator.translate(text, src='en', dest=target_language).text if text else None for text in df[col].tolist()]\n",
    "        translated_columns[col] = translations\n",
    "\n",
    "    translated_df = pd.DataFrame(translated_columns)\n",
    "    return translated_df\n",
    "\n",
    "translated_df = translate_dataframe(test)\n",
    "print(translated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Sector</th>\n",
       "      <th>translated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corteva, Inc. is a global provider of seed and...</td>\n",
       "      <td>Materials</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alico, Inc. is an agribusiness and land manage...</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Limoneira Company is primarily an agribusiness...</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S&amp;W Seed Company (S&amp;W) is a multi-crop and mid...</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tejon Ranch Co. is a diversified real estate d...</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cal-Maine Foods, Inc. is a producer and distri...</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BrightView Holdings, Inc. is a commercial land...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cleveland-Cliffs Inc. is an integrated mining ...</td>\n",
       "      <td>Materials</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Freeport-McMoRan Inc. (FCX) is a mining compan...</td>\n",
       "      <td>Materials</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Solitario Zinc Corp.(Solitario) is a natural r...</td>\n",
       "      <td>Materials</td>\n",
       "      <td>QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description            Sector  \\\n",
       "0  Corteva, Inc. is a global provider of seed and...         Materials   \n",
       "1  Alico, Inc. is an agribusiness and land manage...  Consumer Staples   \n",
       "2  Limoneira Company is primarily an agribusiness...  Consumer Staples   \n",
       "3  S&W Seed Company (S&W) is a multi-crop and mid...  Consumer Staples   \n",
       "4  Tejon Ranch Co. is a diversified real estate d...       Real Estate   \n",
       "5  Cal-Maine Foods, Inc. is a producer and distri...  Consumer Staples   \n",
       "6  BrightView Holdings, Inc. is a commercial land...       Industrials   \n",
       "7  Cleveland-Cliffs Inc. is an integrated mining ...         Materials   \n",
       "8  Freeport-McMoRan Inc. (FCX) is a mining compan...         Materials   \n",
       "9  Solitario Zinc Corp.(Solitario) is a natural r...         Materials   \n",
       "\n",
       "                                     translated_text  \n",
       "0  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "1  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "2  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "3  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "4  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "5  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "6  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "7  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "8  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  \n",
       "9  QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BART_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m predicted_labels\u001b[39m=\u001b[39m[]\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m text:\n\u001b[1;32m---> 10\u001b[0m     prediction \u001b[39m=\u001b[39m BART_classifier(sentence, labels, hypothesis_template\u001b[39m=\u001b[39mhypothesis_template, multi_label\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m     predicted_labels\u001b[39m.\u001b[39mappend(prediction[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BART_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "#Predict Sector with 1st version BART\n",
    "\n",
    "labels = df2_sector['Sector'].unique()\n",
    "text = df2_sector['Description'].head(n=3)\n",
    "\n",
    "hypothesis_template = 'This text is about {}.'\n",
    "predicted_labels=[]\n",
    "for sentence in text:\n",
    "\n",
    "    prediction = BART_classifier(sentence, labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
    "    \n",
    "    predicted_labels.append(prediction['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            min        mean      max\n",
      "char_count           145.000000  829.929707  886.000\n",
      "word_count            29.000000  156.594148  212.000\n",
      "sentence_count         2.000000    6.275763   12.000\n",
      "avg_word_length        3.985849    5.319662    6.928\n",
      "avg_sentence_lenght   13.625000   26.273055   90.000\n"
     ]
    }
   ],
   "source": [
    "#Text tests\n",
    "from nlp_utils import *\n",
    "import math\n",
    "\n",
    "#df2_sector['Description'].iloc[0]\n",
    "#df2_sector.iloc[0]\n",
    "dt_text_things = add_text_length(df2_sector, 'Description')\n",
    "#max_len = math.floor(dt_text_things['word_count'].mean())\n",
    "#max_len = dt_text_things['word_count'].m\n",
    "#lst=bart(df2_sector['Description'].iloc[0:3], max_len)\n",
    "\n",
    "#a=nltk.word_tokenize(df2_sector['Description'].iloc[4])\n",
    "#print(len(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.58k/1.58k [00:00<00:00, 792kB/s]\n",
      "c:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.63G/1.63G [02:42<00:00, 10.0MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 363/363 [00:00<00:00, 181kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.67MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.35MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 3.18MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Text cleanning\n",
    "\n",
    "#max_len = math.floor(dt_text_things['word_count'].mean())\n",
    "#max_len = dt_text_things['word_count'].min()\n",
    "max_len = 100\n",
    "lst=bart(df2_sector['Description'].head(500), max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------NORMAL TEXT--------------------------------------\n",
      "['Corteva, Inc. is a global provider of seed and crop protection solutions focused on the agriculture industry. Its seed segment is engaged in developing and supplying germplasm and traits that produce optimum yields for farms around the world. This segment offers trait technologies that improve resistance to weather, disease, insects and herbicides used to control weeds, and trait technologies that enhance food and nutritional characteristics, and provides digital solutions that assist farmers in decision-making. Its crop protection segment serves the global agricultural input industry with products that protect against weeds, insects and other pests, and disease, and that improve overall crop health both above and below ground through nitrogen management and seed-applied technologies. This segment provides herbicides, insecticides, nitrogen stabilizers and pasture and range management herbicides. Its portfolio of brands includes CLOSER, DELEGATE, Pioneer, Brevant seeds and others.']\n",
      "\n",
      "--------------------------------------SUMMAR TEXT--------------------------------------\n",
      " Corteva, Inc. is a global provider of seed and crop protection solutions focused on the agriculture industry. Its seed segment is engaged in developing and supplying germplasm and traits that produce optimum yields for farms around the world. Its crop protection segment provides herbicides, insecticides, nitrogen stabilizers and pasture and range management herbicides.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"--------------------------------------NORMAL TEXT--------------------------------------\\n{df2_sector['Description'].iloc[0:1].values}\")\n",
    "print()\n",
    "print(f'--------------------------------------SUMMAR TEXT--------------------------------------\\n{lst[0]}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.head(500)\n",
    "df3.insert(1,'Description Summarized',lst)\n",
    "df3.to_csv('US_stocks_500_summ_face_bart_large_cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alico, Inc. is an agribusiness and land management company. The Company's principal lines of business are citrus groves and conservation. Its segments include Alico Citrus and Land Management and Other Operations. The company owns approximately 81,000 acres of land and approximately 90,00 acres of mineral rights throughout Florida.\n",
      "Alico, Inc. is an agribusiness and land management company. The Company's principal lines of business are citrus groves and conservation. The Alico Citrus segment owns and manages citrus land in DeSoto, Polk, Collier, Hendry, Charlotte, Highlands, and Hardee Counties in Florida. The Land Management and Other Operations segment is engaged in land leasing for recreational and grazing purposes.\n"
     ]
    }
   ],
   "source": [
    "print(df3['Description Summarized'].iloc[1])\n",
    "print(\"Alico, Inc. is an agribusiness and land management company. The Company's principal lines of business are citrus groves and conservation. The Alico Citrus segment owns and manages citrus land in DeSoto, Polk, Collier, Hendry, Charlotte, Highlands, and Hardee Counties in Florida. The Land Management and Other Operations segment is engaged in land leasing for recreational and grazing purposes.\")\n",
    "#print(df2['Description'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Sector with 2nd version BART\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AyoubChLin/Bart-MNLI-CNN_news\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"AyoubChLin/Bart-MNLI-CNN_news\")\n",
    "classifier = transformers.pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarized = pd.read_csv('datasets/US_stocks_500_summ_default.csv')\n",
    "labels = df_summarized['Sector'].unique()\n",
    "sentences = df_summarized['Description Summarized'].head(n=500)\n",
    "df=df_summarized.head(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = [classifier(sentence, labels, multi_label=True) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label=[prediction[i]['labels'][0] for i in range(df_summarized.shape[0])]\n",
    "df_summarized['Predicted Label'] = predicted_label\n",
    "df_summarized.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Industrials', 'Industrials', 'Industrials']\n",
      "                                         Description            Sector\n",
      "0  Corteva, Inc. is a global provider of seed and...         Materials\n",
      "1  Alico, Inc. is an agribusiness and land manage...  Consumer Staples\n",
      "2  Limoneira Company is primarily an agribusiness...  Consumer Staples\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)\n",
    "print(df2_sector.head(n=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
