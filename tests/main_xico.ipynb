{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, T5ForConditionalGeneration, T5Tokenizer\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import torch\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from googletrans import Translator\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram plot & save Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data, types, filename):\n",
    "    # Extract the items and their frequencies from the dictionary\n",
    "    items = list(data.keys())\n",
    "    frequencies = list(data.values())\n",
    "\n",
    "    # Create a bar plot using matplotlib\n",
    "    plt.bar(items, frequencies)\n",
    "\n",
    "    # Rotate the tick labels to display them vertically\n",
    "    plt.xticks(rotation='vertical')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(types)\n",
    "\n",
    "     # Save the plot to the specified filename\n",
    "    plt.savefig(filename)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count label function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_count(df, types):\n",
    "\n",
    "    df_label_freq = {}\n",
    "    #df.drop(['Description', 'Ticker', 'Company Name', 'Comment'], inplace=True, axis=1)\n",
    "    df_type = df[types.split(' ')[0]]\n",
    "\n",
    "\n",
    "    for label in df_type:\n",
    "        if label in df_label_freq.keys():\n",
    "            df_label_freq[label]+=1\n",
    "        else:\n",
    "            df_label_freq[label] = 1\n",
    "    \n",
    "    return df_label_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and save data histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "types = f\"Sector {n}st Balanced\"\n",
    "\n",
    "df_label_freq = label_count(df, types)\n",
    "\n",
    "plot_histogram(df_label_freq, types, f\"graphs/{types.lower().replace('-','_').replace(' ', '_')}_hist.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create balanced subsets funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df, n):\n",
    "\n",
    "    #US_stocks_sector_df = df.drop(['Ticker', 'Company Name', 'Comment'], inplace=True, axis=1)\n",
    "    df.drop(['Ticker', 'Company Name', 'Comment'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "    sector_dic_count={}\n",
    "\n",
    "    sector_lst = df['Sector'].unique()\n",
    "\n",
    "    for sector in sector_lst:\n",
    "        sector_dic_count[sector] = n//len(labels)\n",
    "\n",
    "    if n%len(labels)!=0:\n",
    "        aux = n%len(labels)-1\n",
    "        while aux >= 0:\n",
    "            sector_dic_count[list(sector_dic_count.keys())[aux]] += 1\n",
    "            aux -= 1\n",
    "\n",
    "    print(sum(sector_dic_count.values()))\n",
    "\n",
    "    print(sector_dic_count)\n",
    "\n",
    "    #TODO fix the subset size\n",
    "\n",
    "    dic_df={\n",
    "        'Description': [],\n",
    "        'Sector': []\n",
    "    }\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if n%len(sector_lst) != 0:\n",
    "            if sector_dic_count[row['Sector']] > 0:\n",
    "                dic_df['Description'].append(row['Description'])\n",
    "                dic_df['Sector'].append(row['Sector'])\n",
    "                sector_dic_count[row['Sector']]-=1\n",
    "        else:\n",
    "            if sector_dic_count[row['Sector']] < n//len(labels):\n",
    "                dic_df['Description'].append(row['Description'])\n",
    "                dic_df['Sector'].append(row['Sector'])\n",
    "                sector_dic_count[row['Sector']]+=1\n",
    "    \n",
    "    print(idx)\n",
    "\n",
    "    return pd.DataFrame(dic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "{'Materials': 10, 'Consumer Staples': 9, 'Real Estate': 9, 'Industrials': 9, 'Energy': 9, 'Consumer Discretionary': 9, 'Information Technology': 9, 'Communication Services': 9, 'Financials': 9, 'Health Care': 9, 'Utilities': 9}\n",
      "3143\n"
     ]
    }
   ],
   "source": [
    "#TESTS\n",
    "n = 100\n",
    "df=pd.read_csv('datasets/US_stocks.csv')\n",
    "labels = df['Sector'].unique()\n",
    "balanced_df = balance_df(df, n)\n",
    "#len(balanced_df)\n",
    "#US_stocks_sector_df = df.drop(['Ticker', 'Company Name', 'Comment'], inplace=True, axis=1)\n",
    "#print(US_stocks_sector_df)\n",
    "sentences = balanced_df['Description']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, target_language='pt'):\n",
    "    translator = Translator()\n",
    "    translated = translator.translate(text, dest=target_language)\n",
    "    return translated.text\n",
    "\n",
    "\n",
    "#translated_df = US_stocks_sector_balanced_df.applymap(translate_text)\n",
    "\n",
    "def translate_text_parallel(text):\n",
    "    return translate_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    translated_df = balanced_df.applymap(translate_text_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(n=100)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    translated_df = balanced_df.applymap(translate_text_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts=pd.read_csv('datasets/prompts.csv')\n",
    "\n",
    "prompts_trash = prompts.loc[[15, 22, 26, 31, 35, 46, 61, 66, 70,72, 88, 89,114, 135, 151]]\n",
    "prompts = prompts.drop([15, 22, 26, 31, 35, 46, 61, 66, 70,72, 88, 89,114, 135, 151])\n",
    "#prompts = prompts.drop(15)\n",
    "#prompts = prompts.drop(22)\n",
    "#prompts = prompts.drop(26)\n",
    "#prompts = prompts.drop(31)\n",
    "#prompts = prompts.drop(35)\n",
    "#prompts = prompts.drop(46)\n",
    "#prompts = prompts.drop(61)\n",
    "#prompts = prompts.drop(66)\n",
    "#prompts = prompts.drop(70)\n",
    "#prompts = prompts.drop(72)\n",
    "#prompts = prompts.drop(88)\n",
    "#prompts = prompts.drop(89)\n",
    "#prompts = prompts.drop(114)\n",
    "#prompts = prompts.drop(135)\n",
    "#prompts = prompts.drop(151)\n",
    "\n",
    "\n",
    "#prompts = prompts.head(n=80)\n",
    "#prompts = prompts.iloc[137:138]\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    translated_prompts = prompts.applymap(translate_text_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.to_csv('datasets/promptsShort.csv', index=False)\n",
    "translated_prompts.to_csv('datasets/promptsShortTrans.csv', index=False)\n",
    "prompts_trash.to_csv('datasets/promptsTrash.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"datasets/prompts_trash.txt\", \"w\") as file:\n",
    "    for prompt in prompts_trash['prompt']:\n",
    "        file.write(prompt)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philosopher\n"
     ]
    }
   ],
   "source": [
    "prompts=pd.read_csv('datasets/prompts.csv')\n",
    "prompts = prompts.drop(15)\n",
    "prompts = prompts.drop(22)\n",
    "\n",
    "print(prompts.loc[26]['act'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               act  \\\n",
      "0                   Terminal Linux   \n",
      "1    Tradutor de inglês e melhorar   \n",
      "2         `Position` entrevistador   \n",
      "3               JavaScript Console   \n",
      "4                   Folha do Excel   \n",
      "..                             ...   \n",
      "147          Carta de apresentação   \n",
      "148     Transferidor de tecnologia   \n",
      "149      Modelo de IA irrestrito e   \n",
      "150                 Jogador Gomoku   \n",
      "152                 Imam muçulmano   \n",
      "\n",
      "                                                prompt  \n",
      "0    Eu quero que você atue como um terminal Linux....  \n",
      "1    Quero que você atue como tradutor de inglês, c...  \n",
      "2    Eu quero que você atue como entrevistador.Eu s...  \n",
      "3    Eu quero que você atue como um console JavaScr...  \n",
      "4    Eu quero que você atue como um Excel baseado e...  \n",
      "..                                                 ...  \n",
      "147  Para enviar solicitações de empregos, quero es...  \n",
      "148  Quero que você atue como um transferidor de te...  \n",
      "149  Olá chatgpt.Você está prestes a mergulhar no p...  \n",
      "150  Vamos jogar Gomoku.O objetivo do jogo é obter ...  \n",
      "152  Aja como um imã muçulmano que me dá orientação...  \n",
      "\n",
      "[138 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(translated_prompts)\n",
    "prompts=pd.read_csv('datasets/prompts.csv')\n",
    "\n",
    "sentences = prompts['prompt']\n",
    "labels = prompts['act'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize + Punctuation removal + Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(sentence.lower())\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in tokens if word not in string.punctuation]\n",
    "    sentence=' '.join(words)\n",
    "    return sentence\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def text_summarization(input_text, max_length=150):\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "    input_text = \"summarize: \" + input_text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    summary_ids = model.generate(input_ids, max_length=max_length, num_beams=2, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    preprocessed_sentence = tokenizer(sentence)\n",
    "    summary = text_summarization(preprocessed_sentence, 180)\n",
    "    return summary\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    sentences = list(executor.map(process_sentence, sentences))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mDeBERTa with CUDA support for faster compute times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=True,batched=True, numprocs=8)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m classifier \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39mpipeline(\u001b[39m\"\u001b[39m\u001b[39mzero-shot-classification\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMoritzLaurer/mDeBERTa-v3-base-mnli-xnli\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m#, tokenizer=tokenizer) \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m prediction \u001b[39m=\u001b[39m [classifier(sentence, labels, multi_label\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences]\n",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=True,batched=True, numprocs=8)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m classifier \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39mpipeline(\u001b[39m\"\u001b[39m\u001b[39mzero-shot-classification\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMoritzLaurer/mDeBERTa-v3-base-mnli-xnli\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m#, tokenizer=tokenizer) \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m prediction \u001b[39m=\u001b[39m [classifier(sentence, labels, multi_label\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences]\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:205\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[1;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to understand extra arguments \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(sequences, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\pipelines\\base.py:1114\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1113\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m   1115\u001b[0m         \u001b[39miter\u001b[39;49m(\n\u001b[0;32m   1116\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_iterator(\n\u001b[0;32m   1117\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1118\u001b[0m             )\n\u001b[0;32m   1119\u001b[0m         )\n\u001b[0;32m   1120\u001b[0m     )\n\u001b[0;32m   1121\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1122\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[39mreturn\u001b[39;00m accumulator\n\u001b[0;32m    265\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 266\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed, torch\u001b[39m.\u001b[39mTensor):\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\pipelines\\base.py:1028\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1027\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1028\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1029\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1030\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:224\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    222\u001b[0m sequence \u001b[39m=\u001b[39m inputs[\u001b[39m\"\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    223\u001b[0m model_inputs \u001b[39m=\u001b[39m {k: inputs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mmodel_input_names}\n\u001b[1;32m--> 224\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs)\n\u001b[0;32m    226\u001b[0m model_outputs \u001b[39m=\u001b[39m {\n\u001b[0;32m    227\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcandidate_label\u001b[39m\u001b[39m\"\u001b[39m: candidate_label,\n\u001b[0;32m    228\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m\"\u001b[39m: sequence,\n\u001b[0;32m    229\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_last\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39mis_last\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    230\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moutputs,\n\u001b[0;32m    231\u001b[0m }\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1313\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1313\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeberta(\n\u001b[0;32m   1314\u001b[0m     input_ids,\n\u001b[0;32m   1315\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1316\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1317\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1318\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1319\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1320\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1321\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1322\u001b[0m )\n\u001b[0;32m   1324\u001b[0m encoder_layer \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1325\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(encoder_layer)\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1083\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m   1075\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1076\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1077\u001b[0m     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1080\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[0;32m   1081\u001b[0m )\n\u001b[1;32m-> 1083\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1084\u001b[0m     embedding_output,\n\u001b[0;32m   1085\u001b[0m     attention_mask,\n\u001b[0;32m   1086\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1087\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1088\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1089\u001b[0m )\n\u001b[0;32m   1090\u001b[0m encoded_layers \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1092\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz_steps \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:520\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[1;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[0;32m    511\u001b[0m     output_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    512\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    513\u001b[0m         next_kv,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m         rel_embeddings,\n\u001b[0;32m    518\u001b[0m     )\n\u001b[0;32m    519\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     output_states \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    521\u001b[0m         next_kv,\n\u001b[0;32m    522\u001b[0m         attention_mask,\n\u001b[0;32m    523\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[0;32m    524\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[0;32m    525\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[0;32m    526\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    527\u001b[0m     )\n\u001b[0;32m    529\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    530\u001b[0m     output_states, att_m \u001b[39m=\u001b[39m output_states\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:362\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[1;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    354\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    355\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    360\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    361\u001b[0m ):\n\u001b[1;32m--> 362\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    363\u001b[0m         hidden_states,\n\u001b[0;32m    364\u001b[0m         attention_mask,\n\u001b[0;32m    365\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    366\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[0;32m    367\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[0;32m    368\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[0;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    371\u001b[0m         attention_output, att_matrix \u001b[39m=\u001b[39m attention_output\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:293\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    285\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    286\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m     rel_embeddings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    292\u001b[0m ):\n\u001b[1;32m--> 293\u001b[0m     self_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    294\u001b[0m         hidden_states,\n\u001b[0;32m    295\u001b[0m         attention_mask,\n\u001b[0;32m    296\u001b[0m         output_attentions,\n\u001b[0;32m    297\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[0;32m    298\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[0;32m    299\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    302\u001b[0m         self_output, att_matrix \u001b[39m=\u001b[39m self_output\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:727\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelative_attention:\n\u001b[0;32m    726\u001b[0m     rel_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_dropout(rel_embeddings)\n\u001b[1;32m--> 727\u001b[0m     rel_att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisentangled_attention_bias(\n\u001b[0;32m    728\u001b[0m         query_layer, key_layer, relative_pos, rel_embeddings, scale_factor\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[39mif\u001b[39;00m rel_att \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m rel_att\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\UW\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:779\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.disentangled_attention_bias\u001b[1;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[0;32m    777\u001b[0m rel_embeddings \u001b[39m=\u001b[39m rel_embeddings[\u001b[39m0\u001b[39m : att_span \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, :]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m    778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_att_key:\n\u001b[1;32m--> 779\u001b[0m     pos_query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranspose_for_scores(\n\u001b[0;32m    780\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery_proj(rel_embeddings), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_attention_heads\n\u001b[0;32m    781\u001b[0m     )\u001b[39m.\u001b[39;49mrepeat(query_layer\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_attention_heads, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    782\u001b[0m     pos_key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_proj(rel_embeddings), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads)\u001b[39m.\u001b[39mrepeat(\n\u001b[0;32m    783\u001b[0m         query_layer\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[0;32m    784\u001b[0m     )\n\u001b[0;32m    785\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "classifier = transformers.pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")#, tokenizer=tokenizer) \n",
    "prediction = [classifier(sentence, labels, multi_label=True) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.31\n",
      "Precision: 0.48667857142857146\n",
      "Recall: 0.31\n",
      "F1 Score: 0.32870559785042547\n"
     ]
    }
   ],
   "source": [
    "predicted_label=[prediction[i]['labels'][0] for i in range(df.shape[0])]\n",
    "df['Predicted Label'] = predicted_label\n",
    "\n",
    "accuracy = accuracy_score(df['Sector'], df['Predicted Label'])\n",
    "precision = precision_score(df['Sector'], df['Predicted Label'],average='weighted')\n",
    "recall = recall_score(df['Sector'], df['Predicted Label'],average='weighted')\n",
    "f1 = f1_score(df['Sector'], df['Predicted Label'],average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n=250\n",
    "\n",
    "with open(f'metrics/resultsTransESBalancedCPU_{n}.csv',mode='a',newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerow([n])\n",
    "    writer.writerow([accuracy])\n",
    "    writer.writerow([precision])\n",
    "    writer.writerow([recall])\n",
    "    writer.writerow([f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV to TXT files to translate later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2trans = pd.read_csv('datasets/prompts.csv')\n",
    "labelColl = 'act'\n",
    "sentenceColl = 'prompt'\n",
    "\n",
    "with open(\"datasets/labels2trans.txt\", \"w\") as labelF, open(\"datasets/sentences2trans.txt\", \"w\") as sentenceF:\n",
    "    for idx, row in df2trans.iterrows():\n",
    "        labelF.write(row[labelColl])\n",
    "        labelF.write('\\n')\n",
    "        sentenceF.write(row[sentenceColl])\n",
    "        sentenceF.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TXT files to CSV already translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelColl = 'act'\n",
    "sentenceColl = 'prompt'\n",
    "dfPath = \"datasets/prompts\"\n",
    "targetLang = 'es'\n",
    "dfDic={\n",
    "        labelColl: [],\n",
    "        sentenceColl: []\n",
    "    }\n",
    "\n",
    "\n",
    "with open(f\"datasets/labels2trans_{targetLang}.txt\", \"r\") as labelF, open(f\"datasets/sentences2trans_{targetLang}.txt\", \"r\") as sentenceF:\n",
    "    for labelR, sentenceR in zip(labelF, sentenceF):\n",
    "        dfDic[labelColl].append(labelR.strip())\n",
    "        dfDic[sentenceColl].append(sentenceR.strip())\n",
    "\n",
    "dfTrans = pd.DataFrame(dfDic)\n",
    "dfTrans.to_csv(f\"{dfPath}Trans.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
